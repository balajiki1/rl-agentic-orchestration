# Reinforcement Learning‚ÄìEnhanced Agentic Research Orchestration System  
### Final Project ‚Äì Reinforcement Learning for Agentic AI Systems  
**Author:** Kishore Balaji  
**Date:** December 2025  

---

## üìå Overview

This project implements a **reinforcement learning‚Äìdriven orchestration system** for research agents.  
When a user submits a query, the system chooses between three research workflows:

- **Fast Summary** (low cost, low depth)  
- **Deep Research** (high cost, high depth)  
- **RAG Retrieval** (balanced cost and depth)

Traditional systems rely on static heuristics.  
Here, I integrate **RL** to build a system that *learns optimal workflow selection through experience*, improving both answer quality and tool efficiency.

This project implements two RL algorithms:

1. **Q-Learning (Value-Based RL)**  
2. **UCB1 (Exploration-Based Bandit Algorithm)**  

The system learns a policy that adapts to query topic, complexity, and prior performance.

---

## üèóÔ∏è System Architecture

![Architecture](report/architecture_modern.png)

### üîÑ Pipeline Description

1. **User Query** enters the system  
2. **State Encoder** extracts:
   - Topic category (Tech / Health / General)  
   - Query length bucket  
   - Prior success/failure  
3. **RL Controller (Q-Learning or UCB)** selects the best workflow  
4. **Workflow Agents** execute:
   - Fast Summary  
   - Deep Research  
   - RAG Retrieval  
5. Output quality + tool usage ‚Üí **reward**  
6. RL controller updates ‚Üí system improves over time  

---

## üß† Reinforcement Learning Methods

### **1Ô∏è‚É£ Q-Learning (Value-Based RL)**

- 18 discrete states  
- 3 actions (workflows)  
- Epsilon-greedy exploration with decay  

Update rule:

\[
Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma \max_{a'} Q(s',a') - Q(s,a)]
\]

---

### **2Ô∏è‚É£ UCB1 (Exploration Strategy)**

Balances exploration & exploitation:

\[
a_t = \arg\max_a \left[\bar{X}_a + c\sqrt{\frac{\ln t}{n_a}} \right]
\]

Provides a strong, simple baseline for comparison.

---

## üß™ Synthetic Training Environment

A simulated environment models realistic agent workflows:

- Each state has a hidden optimal workflow  
- Quality scores sampled from a normal distribution  
- Tool costs included  
- Reward used for training:

\[
R = 1.0 \times \text{quality} - 0.2 \times \text{tools used}
\]

---

# ‚öôÔ∏è Installation & Setup

Clone the project:

```bash
git clone https://github.com/your-username/rl-agentic-orchestration.git
cd rl-agentic-orchestration
